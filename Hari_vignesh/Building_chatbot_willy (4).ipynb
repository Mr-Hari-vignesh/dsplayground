{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jIK1bZB6Hc0",
        "outputId": "3c95f369-2a76-4265-c02c-8a262d506178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import string \n",
        "import random\n",
        "import nltk\n",
        "nltk.download('popular')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yASq0j8kEKZW"
      },
      "source": [
        "# Removing Runtime(warnings) from output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P9jhmHTVAp3Z"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVWs28mysqTF"
      },
      "source": [
        "# Importing and Reading the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw0g7u6G2zXY",
        "outputId": "ef71c43a-8804-401d-87c9-db2215869714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "f = open(\"/content/for_testing_chatbot.txt\",\"r\", errors = \"ignore\")\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower() #converts text to lowercase\n",
        "nltk.download(\"punkt\") #using the punkit tokenizer\n",
        "nltk.download(\"wordnet\") #using the wordnet library\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc) #convert doc to list of sentence \n",
        "word_tokens = nltk.word_tokenize(raw_doc) #concert doc to list of wc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LatnmNFAGcZU"
      },
      "source": [
        "# Example of sent tokens "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HgI79JjtyE4",
        "outputId": "6e4c275e-dfeb-4c4e-9b7e-a29b90ba7053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' diggibyte and cuelebre is end to end technology services provider for your data anlaytics needs right from building strategy to architecting the platform and\\n to the deployment of dashboards in cloud/on-prem and we work with modern tools and technologies that modernize,\\n automate & support in solving data challenges with ai & ml by finding the right trends & patterns and we excel in leveraging the most advanced technologies,\\n to accelerate your day-to-day operations and increase business process efficiency by playing around your data to derive valuable outcomes\\n diggibyte solve your business problems by integrating your data engineering and advanced analytics tools & technologies \\n to visit home page : https://diggibyte.com/index.html).', '(address of the diggibyte technologies private limited: (connect with us to achieve new milestones and win your customers)\\n address        : diggibyte technologies private limited,novel tech park,3rd floo,kudlu gate,muneshwara nagar bengaluru,karnataka-560068\\n google location: https://www.google.com/maps/place/novel+tech+park/@12.8914639,77.6414856,17z/data=!3m1!4b1!4m5!3m4!1s0x3bae14b0129745ff:0xf9d4a7aab0502205!8m2!3d12.8914639!4d77.6414856 visit \\n website        : info@diggibyte.com)\\n contact of our sales team  at [sales:sales@diggibyte.com  mobile number: +91-8110889199] \\n contact our human resourse at [hr   :hr@diggibyte.com     mobile number: +91-8110889599].', \"(our valuable partner of diggibyte technologies is [ databricks ] \\n about databricks : our partnership with databricks allows us to leverage scaled computation and advanced machine learning capabilities among databricks' out-of-the-box capacities,\\n databricks is a pioneer and leader in the field,\\n in addition, we have data engineers and data analysts certified in databricks,these experts offer consulting services to help organizations implement real-time solutions and deliver actual value from data,\\n databricks has seamless integration with leading cloud providers such as azure aws and google cloud platform, facilitating processing data needed for advanced ml implementations,\\n diggibyte also has pluggable and customizable assets that integrate with databricks and speed up data onboarding,\\n in addition, diggibyte's team of certified professionals are skilled and proficient in databricks implantation and architectural solution design we set up, develop,\\n and maintain the data pipeline and data analytics solutions on the databricks platform, our databricks partnership allows us to gain exclusive access to new features,\\n training, and resources that directly enable us to solve data challenges for our customers in the most efficient way link: https://diggibyte.com/partners.html#.)\", \"(careers at diggibyte we're more than just a workplace, we're a family,\\n we know that finding a meaningful and rewarding job can be a long journey, our goal is to make that process as easy as possible for you,\\n and to create a work environment that's satisfying - one where you'll look forward to coming to every day,\\n start your journey with us by browsing available jobs link: https://diggibyte.zohorecruit.in/jobs/careers-diggibyte ).\", '(service that provide by diggibyte is:\\n 1) advisory and consulting         : to know more click here : https://diggibyte.com/advisory-consulting.html\\n 2) data and platform engineering   : to know more click here : https://diggibyte.com/data-platform-engg.html\\n 3) data science ai/ml              : to know more click here : https://diggibyte.com/data-science.html\\n 4) advanced and business analytics : to know more click here : https://diggibyte.com/advanced-business-analytics.html\\n 5) devops and maintanance          : to know more click here : https://diggibyte.com/advanced-business-analytics.html ).', \"(resource of our diggibyte technologies are:\\n blog's            : visit : https://blogs.diggibyte.com/\\n whitepaper/e-book : visit : https://blogs.diggibyte.com/whitepaper-e-books/ ).\", '(we combine the latest tools and technologies to accelerate your business growth and increase productivity and efficiency:\\n tools are : \\n1)apache airflow\\n2)amazon athena\\n3)azure iot hub \\n4)beam\\n5)azure devops\\n6)jenkins\\n7)kafka\\n8)knime\\n9)kubernets\\n10)maven\\n11)mongo db\\n12)nosql-net\\n13)amazon redshift\\n14)apache spark\\n15)tensorfow\\n16)docker\\n17)sql  \\nthese are the tools we using in our organization).', '.--------------------------------------------------------------------------------------------------------------------------------.', '(data science is an interdisciplinary field that uses scientific methods, processes,\\n algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured and unstructured data,\\n and apply knowledge from data across a broad range of application domains\\n[statistics,\\n visualization,\\n deep learning,\\n machine learning are important data science concepts]\\n to know more visit here: https://en.wikipedia.org/wiki/data_science ).', '(data engineers build systems for collecting, validating, and preparing that high-quality data,\\n data engineers gather and prepare the data and data scientists use the data to promote better business decisions\\n in order to perform their responsibilities efficiently and effectively, data engineers must possess the following technical and soft skills:\\n1)coding\\n2)data warehousing\\n3)knowledge of operating systems\\n4)database systems\\n5)data analysis\\n6)critical thinking skills\\n7)basic understanding of machine learning\\n8)communication skills\\nto know more visit here : https://en.wikipedia.org/wiki/data_engineering ).', '(powerbi is a collection of software services, apps, and connectors that work together to turn your unrelated sources of data into coherent,\\n visually immersive, and interactive insights, your data may be an excel spreadsheet,\\n or a collection of cloud-based and on-premises hybrid data warehouses,\\n one of the most important skills that a power bi developer must have is proficiency or familiarity with data science, business intelligence, and data analytics,\\n power bi developer must also be aware of :\\n1) data integration\\n2) data warehousing, \\n3) modeling along with presentation tactics and concepts\\nto know more visit here : https://en.wikipedia.org/wiki/microsoft_power_bi ).', '(a full stack web developer is a person who can develop both client and server software\\n in addition to mastering html and css, he/she also knows how to: program a browser (like using javascript, jquery, angular, or vue) \\n program a server (like using php, asp, python, or node)\\n to know more visit here : https://en.wikipedia.org/wiki/full_stack ).', '(a devops engineer is an it generalist who should have a wide-ranging knowledge of both development and operations,\\n including coding, infrastructure management, system administration, and devops toolchains,\\n devops engineers should also possess interpersonal skills since they work across company silos to create a more collaborative environment\\nto know more visit here : https://en.wikipedia.org/wiki/devops ).', '.------------------------------------------------------------------------------------------------------------------------.', '(python is a high-level, general-purpose programming language,\\n its design philosophy emphasizes code readability with the use of significant indentation,\\n python is dynamically-typed and garbage-collected,\\n it supports multiple programming paradigms, including structured, object-oriented and functional programming).', '(pyspark is an interface for apache spark ,\\n it not only allows you to write spark applications using python apis,\\n but also provides the pyspark shell for interactively analyzing your data in a distributed environment\\n pyspark supports most of spark’s features such as spark sql, dataframe, streaming, mllib (machine learning) and spark core).', '(sql is a domain-specific language used in programming and designed for managing data held in a relational database management system,\\n or for stream processing in a relational data stream management system ).', '(java is a high-level, class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible).', \"(c is a general-purpose computer programming language, it was created in the 1970s by dennis ritchie, and remains very widely used and influential,\\n by design, c's features cleanly reflect the capabilities of the targeted cpus )\\n the c programming language is the recommended language for creating embedded system drivers and applications,\\n the availability of machine-level hardware apis, as well as the presence of c compilers, dynamic memory allocation,\\n and deterministic resource consumption, make this language the most popular ).\", '(machine language is a low-level language made up of binary numbers or bits that a computer can understand,\\n it is also known as machine code or object code and is extremely tough to comprehend, the only language that the computer understands is machine language,\\n all programmes and programming languages, such as swift and c++, produce or run programmes in machine language before they are run on a computer, when a specific task,\\n even the smallest process executes, machine language is transported to the system processor, computers are only able to understand binary data as they are digital devices).', '(deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example,\\n deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost ).', '(artificial intelligence (ai) is the branch of computer sciences that emphasizes the development of intelligence machines, thinking and working like humans, for example,\\n speech recognition, problem-solving, learning and planning).']\n"
          ]
        }
      ],
      "source": [
        "print(sent_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1c1hyqVGszv",
        "outputId": "bb30c26e-df23-4dd9-8224-d9b16d2e2cb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' diggibyte and cuelebre is end to end technology services provider for your data anlaytics needs right from building strategy to architecting the platform and\\n to the deployment of dashboards in cloud/on-prem and we work with modern tools and technologies that modernize,\\n automate & support in solving data challenges with ai & ml by finding the right trends & patterns and we excel in leveraging the most advanced technologies,\\n to accelerate your day-to-day operations and increase business process efficiency by playing around your data to derive valuable outcomes\\n diggibyte solve your business problems by integrating your data engineering and advanced analytics tools & technologies \\n to visit home page : https://diggibyte.com/index.html).',\n",
              " '(address of the diggibyte technologies private limited: (connect with us to achieve new milestones and win your customers)\\n address        : diggibyte technologies private limited,novel tech park,3rd floo,kudlu gate,muneshwara nagar bengaluru,karnataka-560068\\n google location: https://www.google.com/maps/place/novel+tech+park/@12.8914639,77.6414856,17z/data=!3m1!4b1!4m5!3m4!1s0x3bae14b0129745ff:0xf9d4a7aab0502205!8m2!3d12.8914639!4d77.6414856 visit \\n website        : info@diggibyte.com)\\n contact of our sales team  at [sales:sales@diggibyte.com  mobile number: +91-8110889199] \\n contact our human resourse at [hr   :hr@diggibyte.com     mobile number: +91-8110889599].']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sent_tokens[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjfnAbJjHRKY"
      },
      "source": [
        "# Example of word tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZkfg80IHU8i",
        "outputId": "7dbd159b-1233-48f0-f929-b20aaf627328"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['diggibyte', 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "word_tokens[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0c2Tb6rvh3o",
        "outputId": "8680fd21-1cf7-4b8a-e36f-f207b808023b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['diggibyte', 'and', 'cuelebre', 'is', 'end', 'to', 'end', 'technology', 'services', 'provider', 'for', 'your', 'data', 'anlaytics', 'needs', 'right', 'from', 'building', 'strategy', 'to', 'architecting', 'the', 'platform', 'and', 'to', 'the', 'deployment', 'of', 'dashboards', 'in', 'cloud/on-prem', 'and', 'we', 'work', 'with', 'modern', 'tools', 'and', 'technologies', 'that', 'modernize', ',', 'automate', '&', 'support', 'in', 'solving', 'data', 'challenges', 'with', 'ai', '&', 'ml', 'by', 'finding', 'the', 'right', 'trends', '&', 'patterns', 'and', 'we', 'excel', 'in', 'leveraging', 'the', 'most', 'advanced', 'technologies', ',', 'to', 'accelerate', 'your', 'day-to-day', 'operations', 'and', 'increase', 'business', 'process', 'efficiency', 'by', 'playing', 'around', 'your', 'data', 'to', 'derive', 'valuable', 'outcomes', 'diggibyte', 'solve', 'your', 'business', 'problems', 'by', 'integrating', 'your', 'data', 'engineering', 'and', 'advanced', 'analytics', 'tools', '&', 'technologies', 'to', 'visit', 'home', 'page', ':', 'https', ':', '//diggibyte.com/index.html', ')', '.', '(', 'address', 'of', 'the', 'diggibyte', 'technologies', 'private', 'limited', ':', '(', 'connect', 'with', 'us', 'to', 'achieve', 'new', 'milestones', 'and', 'win', 'your', 'customers', ')', 'address', ':', 'diggibyte', 'technologies', 'private', 'limited', ',', 'novel', 'tech', 'park,3rd', 'floo', ',', 'kudlu', 'gate', ',', 'muneshwara', 'nagar', 'bengaluru', ',', 'karnataka-560068', 'google', 'location', ':', 'https', ':', '//www.google.com/maps/place/novel+tech+park/', '@', '12.8914639,77.6414856,17z/data=', '!', '3m1', '!', '4b1', '!', '4m5', '!', '3m4', '!', '1s0x3bae14b0129745ff:0xf9d4a7aab0502205', '!', '8m2', '!', '3d12.8914639', '!', '4d77.6414856', 'visit', 'website', ':', 'info', '@', 'diggibyte.com', ')', 'contact', 'of', 'our', 'sales', 'team', 'at', '[', 'sales', ':', 'sales', '@', 'diggibyte.com', 'mobile', 'number', ':', '+91-8110889199', ']', 'contact', 'our', 'human', 'resourse', 'at', '[', 'hr', ':', 'hr', '@', 'diggibyte.com', 'mobile', 'number', ':', '+91-8110889599', ']', '.', '(', 'our', 'valuable', 'partner', 'of', 'diggibyte', 'technologies', 'is', '[', 'databricks', ']', 'about', 'databricks', ':', 'our', 'partnership', 'with', 'databricks', 'allows', 'us', 'to', 'leverage', 'scaled', 'computation', 'and', 'advanced', 'machine', 'learning', 'capabilities', 'among', 'databricks', \"'\", 'out-of-the-box', 'capacities', ',', 'databricks', 'is', 'a', 'pioneer', 'and', 'leader', 'in', 'the', 'field', ',', 'in', 'addition', ',', 'we', 'have', 'data', 'engineers', 'and', 'data', 'analysts', 'certified', 'in', 'databricks', ',', 'these', 'experts', 'offer', 'consulting', 'services', 'to', 'help', 'organizations', 'implement', 'real-time', 'solutions', 'and', 'deliver', 'actual', 'value', 'from', 'data', ',', 'databricks', 'has', 'seamless', 'integration', 'with', 'leading', 'cloud', 'providers', 'such', 'as', 'azure', 'aws', 'and', 'google', 'cloud', 'platform', ',', 'facilitating', 'processing', 'data', 'needed', 'for', 'advanced', 'ml', 'implementations', ',', 'diggibyte', 'also', 'has', 'pluggable', 'and', 'customizable', 'assets', 'that', 'integrate', 'with', 'databricks', 'and', 'speed', 'up', 'data', 'onboarding', ',', 'in', 'addition', ',', 'diggibyte', \"'s\", 'team', 'of', 'certified', 'professionals', 'are', 'skilled', 'and', 'proficient', 'in', 'databricks', 'implantation', 'and', 'architectural', 'solution', 'design', 'we', 'set', 'up', ',', 'develop', ',', 'and', 'maintain', 'the', 'data', 'pipeline', 'and', 'data', 'analytics', 'solutions', 'on', 'the', 'databricks', 'platform', ',', 'our', 'databricks', 'partnership', 'allows', 'us', 'to', 'gain', 'exclusive', 'access', 'to', 'new', 'features', ',', 'training', ',', 'and', 'resources', 'that', 'directly', 'enable', 'us', 'to', 'solve', 'data', 'challenges', 'for', 'our', 'customers', 'in', 'the', 'most', 'efficient', 'way', 'link', ':', 'https', ':', '//diggibyte.com/partners.html', '#', '.', ')', '(', 'careers', 'at', 'diggibyte', 'we', \"'re\", 'more', 'than', 'just', 'a', 'workplace', ',', 'we', \"'re\", 'a', 'family', ',', 'we', 'know', 'that', 'finding', 'a', 'meaningful', 'and', 'rewarding', 'job', 'can', 'be', 'a', 'long', 'journey', ',', 'our', 'goal', 'is', 'to', 'make', 'that', 'process', 'as', 'easy', 'as', 'possible', 'for', 'you', ',', 'and', 'to', 'create', 'a', 'work', 'environment', 'that', \"'s\", 'satisfying', '-', 'one', 'where', 'you', \"'ll\", 'look', 'forward', 'to', 'coming', 'to', 'every', 'day', ',', 'start', 'your', 'journey', 'with', 'us', 'by', 'browsing', 'available', 'jobs', 'link', ':', 'https', ':', '//diggibyte.zohorecruit.in/jobs/careers-diggibyte', ')', '.', '(', 'service', 'that', 'provide', 'by', 'diggibyte', 'is', ':', '1', ')', 'advisory', 'and', 'consulting', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/advisory-consulting.html', '2', ')', 'data', 'and', 'platform', 'engineering', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/data-platform-engg.html', '3', ')', 'data', 'science', 'ai/ml', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/data-science.html', '4', ')', 'advanced', 'and', 'business', 'analytics', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/advanced-business-analytics.html', '5', ')', 'devops', 'and', 'maintanance', ':', 'to', 'know', 'more', 'click', 'here', ':', 'https', ':', '//diggibyte.com/advanced-business-analytics.html', ')', '.', '(', 'resource', 'of', 'our', 'diggibyte', 'technologies', 'are', ':', 'blog', \"'s\", ':', 'visit', ':', 'https', ':', '//blogs.diggibyte.com/', 'whitepaper/e-book', ':', 'visit', ':', 'https', ':', '//blogs.diggibyte.com/whitepaper-e-books/', ')', '.', '(', 'we', 'combine', 'the', 'latest', 'tools', 'and', 'technologies', 'to', 'accelerate', 'your', 'business', 'growth', 'and', 'increase', 'productivity', 'and', 'efficiency', ':', 'tools', 'are', ':', '1', ')', 'apache', 'airflow', '2', ')', 'amazon', 'athena', '3', ')', 'azure', 'iot', 'hub', '4', ')', 'beam', '5', ')', 'azure', 'devops', '6', ')', 'jenkins', '7', ')', 'kafka', '8', ')', 'knime', '9', ')', 'kubernets', '10', ')', 'maven', '11', ')', 'mongo', 'db', '12', ')', 'nosql-net', '13', ')', 'amazon', 'redshift', '14', ')', 'apache', 'spark', '15', ')', 'tensorfow', '16', ')', 'docker', '17', ')', 'sql', 'these', 'are', 'the', 'tools', 'we', 'using', 'in', 'our', 'organization', ')', '.', '.', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '.', '(', 'data', 'science', 'is', 'an', 'interdisciplinary', 'field', 'that', 'uses', 'scientific', 'methods', ',', 'processes', ',', 'algorithms', 'and', 'systems', 'to', 'extract', 'or', 'extrapolate', 'knowledge', 'and', 'insights', 'from', 'noisy', ',', 'structured', 'and', 'unstructured', 'data', ',', 'and', 'apply', 'knowledge', 'from', 'data', 'across', 'a', 'broad', 'range', 'of', 'application', 'domains', '[', 'statistics', ',', 'visualization', ',', 'deep', 'learning', ',', 'machine', 'learning', 'are', 'important', 'data', 'science', 'concepts', ']', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/data_science', ')', '.', '(', 'data', 'engineers', 'build', 'systems', 'for', 'collecting', ',', 'validating', ',', 'and', 'preparing', 'that', 'high-quality', 'data', ',', 'data', 'engineers', 'gather', 'and', 'prepare', 'the', 'data', 'and', 'data', 'scientists', 'use', 'the', 'data', 'to', 'promote', 'better', 'business', 'decisions', 'in', 'order', 'to', 'perform', 'their', 'responsibilities', 'efficiently', 'and', 'effectively', ',', 'data', 'engineers', 'must', 'possess', 'the', 'following', 'technical', 'and', 'soft', 'skills', ':', '1', ')', 'coding', '2', ')', 'data', 'warehousing', '3', ')', 'knowledge', 'of', 'operating', 'systems', '4', ')', 'database', 'systems', '5', ')', 'data', 'analysis', '6', ')', 'critical', 'thinking', 'skills', '7', ')', 'basic', 'understanding', 'of', 'machine', 'learning', '8', ')', 'communication', 'skills', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/data_engineering', ')', '.', '(', 'powerbi', 'is', 'a', 'collection', 'of', 'software', 'services', ',', 'apps', ',', 'and', 'connectors', 'that', 'work', 'together', 'to', 'turn', 'your', 'unrelated', 'sources', 'of', 'data', 'into', 'coherent', ',', 'visually', 'immersive', ',', 'and', 'interactive', 'insights', ',', 'your', 'data', 'may', 'be', 'an', 'excel', 'spreadsheet', ',', 'or', 'a', 'collection', 'of', 'cloud-based', 'and', 'on-premises', 'hybrid', 'data', 'warehouses', ',', 'one', 'of', 'the', 'most', 'important', 'skills', 'that', 'a', 'power', 'bi', 'developer', 'must', 'have', 'is', 'proficiency', 'or', 'familiarity', 'with', 'data', 'science', ',', 'business', 'intelligence', ',', 'and', 'data', 'analytics', ',', 'power', 'bi', 'developer', 'must', 'also', 'be', 'aware', 'of', ':', '1', ')', 'data', 'integration', '2', ')', 'data', 'warehousing', ',', '3', ')', 'modeling', 'along', 'with', 'presentation', 'tactics', 'and', 'concepts', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/microsoft_power_bi', ')', '.', '(', 'a', 'full', 'stack', 'web', 'developer', 'is', 'a', 'person', 'who', 'can', 'develop', 'both', 'client', 'and', 'server', 'software', 'in', 'addition', 'to', 'mastering', 'html', 'and', 'css', ',', 'he/she', 'also', 'knows', 'how', 'to', ':', 'program', 'a', 'browser', '(', 'like', 'using', 'javascript', ',', 'jquery', ',', 'angular', ',', 'or', 'vue', ')', 'program', 'a', 'server', '(', 'like', 'using', 'php', ',', 'asp', ',', 'python', ',', 'or', 'node', ')', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/full_stack', ')', '.', '(', 'a', 'devops', 'engineer', 'is', 'an', 'it', 'generalist', 'who', 'should', 'have', 'a', 'wide-ranging', 'knowledge', 'of', 'both', 'development', 'and', 'operations', ',', 'including', 'coding', ',', 'infrastructure', 'management', ',', 'system', 'administration', ',', 'and', 'devops', 'toolchains', ',', 'devops', 'engineers', 'should', 'also', 'possess', 'interpersonal', 'skills', 'since', 'they', 'work', 'across', 'company', 'silos', 'to', 'create', 'a', 'more', 'collaborative', 'environment', 'to', 'know', 'more', 'visit', 'here', ':', 'https', ':', '//en.wikipedia.org/wiki/devops', ')', '.', '.', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '.', '(', 'python', 'is', 'a', 'high-level', ',', 'general-purpose', 'programming', 'language', ',', 'its', 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'with', 'the', 'use', 'of', 'significant', 'indentation', ',', 'python', 'is', 'dynamically-typed', 'and', 'garbage-collected', ',', 'it', 'supports', 'multiple', 'programming', 'paradigms', ',', 'including', 'structured', ',', 'object-oriented', 'and', 'functional', 'programming', ')', '.', '(', 'pyspark', 'is', 'an', 'interface', 'for', 'apache', 'spark', ',', 'it', 'not', 'only', 'allows', 'you', 'to', 'write', 'spark', 'applications', 'using', 'python', 'apis', ',', 'but', 'also', 'provides', 'the', 'pyspark', 'shell', 'for', 'interactively', 'analyzing', 'your', 'data', 'in', 'a', 'distributed', 'environment', 'pyspark', 'supports', 'most', 'of', 'spark', '’', 's', 'features', 'such', 'as', 'spark', 'sql', ',', 'dataframe', ',', 'streaming', ',', 'mllib', '(', 'machine', 'learning', ')', 'and', 'spark', 'core', ')', '.', '(', 'sql', 'is', 'a', 'domain-specific', 'language', 'used', 'in', 'programming', 'and', 'designed', 'for', 'managing', 'data', 'held', 'in', 'a', 'relational', 'database', 'management', 'system', ',', 'or', 'for', 'stream', 'processing', 'in', 'a', 'relational', 'data', 'stream', 'management', 'system', ')', '.', '(', 'java', 'is', 'a', 'high-level', ',', 'class-based', ',', 'object-oriented', 'programming', 'language', 'that', 'is', 'designed', 'to', 'have', 'as', 'few', 'implementation', 'dependencies', 'as', 'possible', ')', '.', '(', 'c', 'is', 'a', 'general-purpose', 'computer', 'programming', 'language', ',', 'it', 'was', 'created', 'in', 'the', '1970s', 'by', 'dennis', 'ritchie', ',', 'and', 'remains', 'very', 'widely', 'used', 'and', 'influential', ',', 'by', 'design', ',', 'c', \"'s\", 'features', 'cleanly', 'reflect', 'the', 'capabilities', 'of', 'the', 'targeted', 'cpus', ')', 'the', 'c', 'programming', 'language', 'is', 'the', 'recommended', 'language', 'for', 'creating', 'embedded', 'system', 'drivers', 'and', 'applications', ',', 'the', 'availability', 'of', 'machine-level', 'hardware', 'apis', ',', 'as', 'well', 'as', 'the', 'presence', 'of', 'c', 'compilers', ',', 'dynamic', 'memory', 'allocation', ',', 'and', 'deterministic', 'resource', 'consumption', ',', 'make', 'this', 'language', 'the', 'most', 'popular', ')', '.', '(', 'machine', 'language', 'is', 'a', 'low-level', 'language', 'made', 'up', 'of', 'binary', 'numbers', 'or', 'bits', 'that', 'a', 'computer', 'can', 'understand', ',', 'it', 'is', 'also', 'known', 'as', 'machine', 'code', 'or', 'object', 'code', 'and', 'is', 'extremely', 'tough', 'to', 'comprehend', ',', 'the', 'only', 'language', 'that', 'the', 'computer', 'understands', 'is', 'machine', 'language', ',', 'all', 'programmes', 'and', 'programming', 'languages', ',', 'such', 'as', 'swift', 'and', 'c++', ',', 'produce', 'or', 'run', 'programmes', 'in', 'machine', 'language', 'before', 'they', 'are', 'run', 'on', 'a', 'computer', ',', 'when', 'a', 'specific', 'task', ',', 'even', 'the', 'smallest', 'process', 'executes', ',', 'machine', 'language', 'is', 'transported', 'to', 'the', 'system', 'processor', ',', 'computers', 'are', 'only', 'able', 'to', 'understand', 'binary', 'data', 'as', 'they', 'are', 'digital', 'devices', ')', '.', '(', 'deep', 'learning', 'is', 'a', 'machine', 'learning', 'technique', 'that', 'teaches', 'computers', 'to', 'do', 'what', 'comes', 'naturally', 'to', 'humans', ':', 'learn', 'by', 'example', ',', 'deep', 'learning', 'is', 'a', 'key', 'technology', 'behind', 'driverless', 'cars', ',', 'enabling', 'them', 'to', 'recognize', 'a', 'stop', 'sign', ',', 'or', 'to', 'distinguish', 'a', 'pedestrian', 'from', 'a', 'lamppost', ')', '.', '(', 'artificial', 'intelligence', '(', 'ai', ')', 'is', 'the', 'branch', 'of', 'computer', 'sciences', 'that', 'emphasizes', 'the', 'development', 'of', 'intelligence', 'machines', ',', 'thinking', 'and', 'working', 'like', 'humans', ',', 'for', 'example', ',', 'speech', 'recognition', ',', 'problem-solving', ',', 'learning', 'and', 'planning', ')', '.']\n"
          ]
        }
      ],
      "source": [
        "print(word_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55fl4QmzHd_Z"
      },
      "source": [
        "# Text pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n2jhPYzLvr27"
      },
      "outputs": [],
      "source": [
        "#wordnet is a semantically-oriented dictonary of english included in NLTK\n",
        "lemonizing = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return[lemonizing.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct),None) for punct in string.punctuation)  \n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.wordpunct_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl82do5aK8WR"
      },
      "source": [
        "# Defining the greeting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YSg7XH08KrM7"
      },
      "outputs": [],
      "source": [
        "Greet_inputs = (\"hello\",\"hi\",\"greetings\",\"sup\",\"whats,up\",\"hey\",\"hie\")\n",
        "Greet_response = (\"hi iam willy\",\"hey friend iam willy\",\"hie there how can i help you\",\"hello iam willy how can i assist you\",\"I am glad! you are talking with me\")\n",
        "def greet(sentance):\n",
        "\n",
        "  for word in sentance.split():\n",
        "    if word.lower() in Greet_inputs:\n",
        "      return random.choice(Greet_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSmWbUE3PKEl"
      },
      "source": [
        "# Response generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L6Ms_brIPOco"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tTYcb9jFOyA_"
      },
      "outputs": [],
      "source": [
        "def response(user_response):\n",
        "  willy1_response=\"\"\n",
        "  TfidVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
        "  tfidf = TfidVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    willy1_response = willy1_response+\"I am sorry ! I didnt understand you\"\n",
        "    return willy1_response\n",
        "  else:\n",
        "    willy1_response = willy1_response+sent_tokens[idx]\n",
        "    return willy1_response  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrj2cmJBPIto"
      },
      "source": [
        "## Defining conversation start/end protocols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yduWOUQyORsD",
        "outputId": "ae899e6c-a075-49ea-ff75-0d0e30399565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: my name is willy.\n",
            "(Iam working for DIGGIBYTE TECHNOLOGIES)\n",
            "How can i assist you, if you like to ( Exit/End-conversation ) any time , just type Bye!\n",
            "hello willy\n",
            "Willy: I am glad! you are talking with me\n",
            "yes..who else i would talk to\n",
            "Willy: I am sorry ! I didnt understand you\n",
            "how do you do willy\n",
            "Willy: I am sorry ! I didnt understand you\n",
            "how do u feel about diggibyte\n",
            "Willy: (address of the diggibyte technologies private limited: (connect with us to achieve new milestones and win your customers)\n",
            " address        : diggibyte technologies private limited,novel tech park,3rd floo,kudlu gate,muneshwara nagar bengaluru,karnataka-560068\n",
            " google location: https://www.google.com/maps/place/novel+tech+park/@12.8914639,77.6414856,17z/data=!3m1!4b1!4m5!3m4!1s0x3bae14b0129745ff:0xf9d4a7aab0502205!8m2!3d12.8914639!4d77.6414856 visit \n",
            " website        : info@diggibyte.com)\n",
            " contact of our sales team  at [sales:sales@diggibyte.com  mobile number: +91-8110889199] \n",
            " contact our human resourse at [hr   :hr@diggibyte.com     mobile number: +91-8110889599].\n",
            "you like to work with diggibyte\n",
            "Willy: (a full stack web developer is a person who can develop both client and server software\n",
            " in addition to mastering html and css, he/she also knows how to: program a browser (like using javascript, jquery, angular, or vue) \n",
            " program a server (like using php, asp, python, or node)\n",
            " to know more visit here : https://en.wikipedia.org/wiki/full_stack ).\n",
            "listen to the question first\n",
            "Willy: I am sorry ! I didnt understand you\n",
            "why are u not understanding me\n",
            "Willy: (our valuable partner of diggibyte technologies is [ databricks ] \n",
            " about databricks : our partnership with databricks allows us to leverage scaled computation and advanced machine learning capabilities among databricks' out-of-the-box capacities,\n",
            " databricks is a pioneer and leader in the field,\n",
            " in addition, we have data engineers and data analysts certified in databricks,these experts offer consulting services to help organizations implement real-time solutions and deliver actual value from data,\n",
            " databricks has seamless integration with leading cloud providers such as azure aws and google cloud platform, facilitating processing data needed for advanced ml implementations,\n",
            " diggibyte also has pluggable and customizable assets that integrate with databricks and speed up data onboarding,\n",
            " in addition, diggibyte's team of certified professionals are skilled and proficient in databricks implantation and architectural solution design we set up, develop,\n",
            " and maintain the data pipeline and data analytics solutions on the databricks platform, our databricks partnership allows us to gain exclusive access to new features,\n",
            " training, and resources that directly enable us to solve data challenges for our customers in the most efficient way link: https://diggibyte.com/partners.html#.)\n",
            "what is data science\n",
            "Willy: (data science is an interdisciplinary field that uses scientific methods, processes,\n",
            " algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured and unstructured data,\n",
            " and apply knowledge from data across a broad range of application domains\n",
            "[statistics,\n",
            " visualization,\n",
            " deep learning,\n",
            " machine learning are important data science concepts]\n",
            " to know more visit here: https://en.wikipedia.org/wiki/data_science ).\n",
            "who is hari?\n",
            "Willy: I am sorry ! I didnt understand you\n",
            "who is your creator\n",
            "Willy: I am sorry ! I didnt understand you\n"
          ]
        }
      ],
      "source": [
        "flag = True\n",
        "print(\"BOT: my name is willy.\\n(Iam working for DIGGIBYTE TECHNOLOGIES)\\nHow can i assist you, if you like to ( Exit/End-conversation ) any time , just type Bye!\")\n",
        "while(flag==True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response!=\"bye\"):\n",
        "    if(user_response==\"thanks\" or user_response==\"thank you\"):\n",
        "      flag=False\n",
        "      print(\"willy: you are welcome..\")\n",
        "    else:\n",
        "      if(greet(user_response)!=None):\n",
        "        print(\"Willy: \"+greet(user_response))\n",
        "      else:\n",
        "        sent_tokens.append(user_response)\n",
        "        word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "        final_words=list(set(word_tokens))\n",
        "        print(\"Willy: \",end=\"\")\n",
        "        print(response(user_response))\n",
        "        sent_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag=False\n",
        "    print(\"willy: Goodbye! Take care ( Thanks for visiting Diggibyte technology)\")         "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K15JWPEgrqno"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}